{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908edd91-da97-484e-9d2d-8b6aca4aa151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 data understanding\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import round as spark_round, col, count, when, isnan, sum as spark_sum, mean, stddev\n",
    "from pyspark.sql.types import IntegerType, FloatType, DoubleType\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c103bacc-0a5f-4548-b946-79de9f6c4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"DataUnderstanding\").getOrCreate()\n",
    "\n",
    "# Load datasets\n",
    "poverty_data = spark.read.csv('multidimensional_poverty.csv', header=True, inferSchema=True)\n",
    "#education_data = spark.read.csv('Inequality in Education.csv', header=True, inferSchema=True)\n",
    "income_data = spark.read.csv('Inequality in Income.csv', header=True, inferSchema=True)\n",
    "gender_ineq_data = spark.read.csv('gender_inequality.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Renaming columns to avoid issues with special characters and spaces\n",
    "poverty_data = poverty_data.withColumnRenamed('Multidimensional Poverty Index (MPI, HDRO)', 'MPI_HDRO') \\\n",
    "    .withColumnRenamed('Population Below $1.25 per Day', 'Population_Below_1_25_per_Day') \\\n",
    "    .withColumnRenamed('Year and Survey', 'Year_and_Survey') \\\n",
    "    .withColumnRenamed('MPI HDRO Percent', 'MPI_HDRO_Percent') \\\n",
    "    .withColumnRenamed('Multidimensional Poverty Index (MPI, 2010)', 'MPI_2010') \\\n",
    "    .withColumnRenamed('MPI 2010 Percent', 'MPI_2010_Percent') \\\n",
    "    .withColumnRenamed('Population in Multidimensional Poverty', 'Population_in_Multidimensional_Poverty') \\\n",
    "    .withColumnRenamed('Intensity of Deprivation', 'Intensity_of_Deprivation') \\\n",
    "    .withColumnRenamed('Education Deprivation', 'Education_Deprivation') \\\n",
    "    .withColumnRenamed('Health Deprivation', 'Health_Deprivation') \\\n",
    "    .withColumnRenamed('Living Standards', 'Living_Standards') \\\n",
    "    .withColumnRenamed('Population Below National Poverty Line', 'Population_Below_National_Poverty_Line')\n",
    "\n",
    "# DataFrame references\n",
    "p_df = poverty_data\n",
    "i_df = income_data\n",
    "g_df = gender_ineq_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0b1f03-ac4f-416a-9f2f-6697295d9822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Year_and_Survey: string (nullable = true)\n",
      " |-- MPI_HDRO: double (nullable = true)\n",
      " |-- MPI_HDRO_Percent: double (nullable = true)\n",
      " |-- MPI_2010: double (nullable = true)\n",
      " |-- MPI_2010_Percent: double (nullable = true)\n",
      " |-- Population_in_Multidimensional_Poverty: string (nullable = true)\n",
      " |-- Intensity_of_Deprivation: double (nullable = true)\n",
      " |-- Education_Deprivation: double (nullable = true)\n",
      " |-- Health_Deprivation: double (nullable = true)\n",
      " |-- Living_Standards: double (nullable = true)\n",
      " |-- Population_Below_National_Poverty_Line: string (nullable = true)\n",
      " |-- Population_Below_1_25_per_Day: string (nullable = true)\n",
      "\n",
      "poverty rows: 101, poverty cols: 13\n",
      "root\n",
      " |-- ISO3: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      " |-- Hemisphere: string (nullable = true)\n",
      " |-- Human Development Groups: string (nullable = true)\n",
      " |-- UNDP Developing Regions: string (nullable = true)\n",
      " |-- HDI Rank (2021): integer (nullable = true)\n",
      " |-- Inequality in income (2010): double (nullable = true)\n",
      " |-- Inequality in income (2011): double (nullable = true)\n",
      " |-- Inequality in income (2012): double (nullable = true)\n",
      " |-- Inequality in income (2013): double (nullable = true)\n",
      " |-- Inequality in income (2014): double (nullable = true)\n",
      " |-- Inequality in income (2015): double (nullable = true)\n",
      " |-- Inequality in income (2016): double (nullable = true)\n",
      " |-- Inequality in income (2017): double (nullable = true)\n",
      " |-- Inequality in income (2018): double (nullable = true)\n",
      " |-- Inequality in income (2019): double (nullable = true)\n",
      " |-- Inequality in income (2020): double (nullable = true)\n",
      " |-- Inequality in income (2021): double (nullable = true)\n",
      "\n",
      "income rows: 195,income cols: 19\n",
      "root\n",
      " |-- GII Rank: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Gender Inequality Index (GII): string (nullable = true)\n",
      " |-- Maternal Mortality Ratio: string (nullable = true)\n",
      " |-- Adolescent Birth Rate: string (nullable = true)\n",
      " |-- Percent Representation in Parliament: string (nullable = true)\n",
      " |-- Population with Secondary Education (Female): string (nullable = true)\n",
      " |-- Population with Secondary Education (Male): string (nullable = true)\n",
      " |-- Labour Force Participation Rate (Female): string (nullable = true)\n",
      " |-- Labour Force Participation Rate (Male): string (nullable = true)\n",
      "\n",
      "gender rows: 195,gender cols: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show DataFrame information\n",
    "# p_df.show()\n",
    "p_df.printSchema()\n",
    "#p_df.describe().show()\n",
    "# get cols and rows\n",
    "p_rows = p_df.count()\n",
    "p_columns = len(p_df.columns)\n",
    "# show cols and rows\n",
    "print(f\"poverty rows: {p_rows}, poverty cols: {p_columns}\")\n",
    "\n",
    "\n",
    "\n",
    "#i_df.show()\n",
    "i_df.printSchema()\n",
    "#i_df.describe().show()\n",
    "# get cols and rows\n",
    "i_rows = i_df.count()\n",
    "i_columns = len(i_df.columns)\n",
    "# show cols and rows\n",
    "print(f\"income rows: {i_rows},income cols: {i_columns}\")\n",
    "\n",
    "#g_df.show()\n",
    "g_df.printSchema()\n",
    "#g_df.describe().show()\n",
    "# get cols and rows\n",
    "g_rows = g_df.count()\n",
    "g_columns = len(g_df.columns)\n",
    "# show cols and rows\n",
    "print(f\"gender rows: {g_rows},gender cols: {g_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b5904-3b90-4e9f-adce-95b07255cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explore Data\n",
    "p_df.describe().show()\n",
    "p_df.printSchema()\n",
    "p_df_desc = p_df.describe()\n",
    "p_df_desc = p_df_desc.select([spark_round(col(c), 2).alias(c) for c in p_df_desc.columns])\n",
    "p_df_desc.show()\n",
    "\n",
    "p_df.select('Health_Deprivation', 'Population_in_Multidimensional_Poverty','Population_Below_National_Poverty_Line', 'Education_Deprivation', 'Living_Standards').describe().show()\n",
    "p_df.groupBy('Country').count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03940c9-d322-4611-9838-4ce9cd17d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = [field.name for field in p_df.schema.fields if isinstance(field.dataType, (IntegerType, FloatType, DoubleType))]\n",
    "numeric_df = p_df.select(numeric_cols)\n",
    "\n",
    "# Compute correlations\n",
    "for col1 in numeric_cols:\n",
    "   for col2 in numeric_cols:\n",
    "        corr_val = p_df.stat.corr(col1, col2)\n",
    "        print(f\"Correlation between {col1} and {col2}: {corr_val:.2f}\")\n",
    "\n",
    "selected_cols = ['Health_Deprivation', 'Population_in_Multidimensional_Poverty','Population_Below_National_Poverty_Line', 'Education_Deprivation', 'Living_Standards']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pandas_df = p_df.select('Population_Below_National_Poverty_Line', 'Education_Deprivation').toPandas()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pandas_df.index, pandas_df['Population_Below_National_Poverty_Line'], label='Population_Below_National_Poverty_Line')\n",
    "plt.plot(pandas_df.index, pandas_df['Education_Deprivation'], label='Education_Deprivation')\n",
    "plt.xlabel('Population_Below_National_Poverty_Line')\n",
    "plt.ylabel('Education_Deprivation')\n",
    "plt.title('Population Below National Poverty Line and Education Deprivation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df3552-acf4-45a5-9cd7-14cd1a0a909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#correlations income\n",
    "i_df.printSchema()\n",
    "selected_cols = ['HDI Rank (2021)', 'Inequality in income (2010)', 'Inequality in income (2011)', 'Inequality in income (2012)','Inequality in income (2013)','Inequality in income (2014)','Inequality in income (2015)','Inequality in income (2016)','Inequality in income (2017)','Inequality in income (2018)','Inequality in income (2019)','Inequality in income (2020)','Inequality in income (2021)']\n",
    "i_df_corr = i_df.select(selected_cols)\n",
    "for col1 in selected_cols:\n",
    "    for col2 in selected_cols:\n",
    "        corr_val = i_df_corr.stat.corr(col1, col2)\n",
    "        print(f\"Correlation between {col1} and {col2}: {corr_val:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g_df=g_df.withColumn('Gender Inequality Index (GII)', col('Gender Inequality Index (GII)').cast(DoubleType()))\n",
    "g_df=g_df.withColumn('Adolescent Birth Rate', col('Adolescent Birth Rate').cast(DoubleType()))\n",
    "g_df=g_df.withColumn('Maternal Mortality Ratio', col('Maternal Mortality Ratio').cast(DoubleType()))\n",
    "g_df=g_df.withColumn('Percent Representation in Parliament', col('Percent Representation in Parliament').cast(DoubleType()))\n",
    "g_df=g_df.withColumn('Population with Secondary Education (Female)', col('Population with Secondary Education (Female)').cast(DoubleType()))\n",
    "g_df=g_df.withColumn('Population with Secondary Education (Male)', col('Population with Secondary Education (Male)').cast(DoubleType()))\n",
    "g_df=g_df.withColumn('Labour Force Participation Rate (Female)', col('Labour Force Participation Rate (Female)').cast(DoubleType()))\n",
    "g_df=g_df.withColumn('Labour Force Participation Rate (Male)', col('Labour Force Participation Rate (Male)').cast(DoubleType()))\n",
    "g_df.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "#correlations gender\n",
    "selected_cols = ['Gender Inequality Index (GII)','Maternal Mortality Ratio','Adolescent Birth Rate','Percent Representation in Parliament','Population with Secondary Education (Female)','Population with Secondary Education (Male)','Labour Force Participation Rate (Female)','Labour Force Participation Rate (Male)']\n",
    "g_df_corr = g_df.select(selected_cols)\n",
    "for col1 in selected_cols:\n",
    "    for col2 in selected_cols:\n",
    "        corr_val = g_df_corr.stat.corr(col1, col2)\n",
    "        print(f\"Correlation between {col1} and {col2}: {corr_val:.2f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da7785-e0c9-4581-9e01-1d0873237e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Visualizations\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert to Pandas DataFrame for visualization\n",
    "pandas_df = p_df.toPandas()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "pandas_df['MPI_HDRO'].plot.hist(title='Histogram of MPI_HDRO')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pandas_df['MPI_HDRO'].plot.density(title='Density Plot of MPI_HDRO')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pandas_df['MPI_HDRO'].plot.box(title='Box Plot of MPI_HDRO')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pandas_df['Education_Deprivation'].value_counts().plot.bar(title='Bar Plot of Education Deprivation')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pandas_df.plot.scatter(x='MPI_HDRO', y='Education_Deprivation', title='Scatter Plot of MPI_HDRO vs. Education Deprivation')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pandas_df.plot.scatter(x='MPI_HDRO', y='Health_Deprivation', title='Scatter Plot of MPI_HDRO vs. Health Deprivation')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pandas_df.plot.scatter(x='MPI_HDRO', y='Living_Standards', title='Scatter Plot of MPI_HDRO vs. Living Standards')\n",
    "plt.show()\n",
    "\n",
    "# Seaborn plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(pandas_df['Education_Deprivation'], kde=True).set_title('Seaborn Histogram and KDE of Education Deprivation')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='MPI_HDRO', y='Education_Deprivation', data=pandas_df).set_title('Violin Plot of MPI_HDRO vs. Education Deprivation')\n",
    "plt.show()\n",
    "\n",
    "# FacetGrid with seaborn\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "g = sns.FacetGrid(pandas_df, row='Education_Deprivation', hue='Education_Deprivation', aspect=3)\n",
    "g.map_dataframe(sns.kdeplot, x='MPI_HDRO', fill=True, alpha=0.5)\n",
    "g.set(yticks=[], ylabel='')\n",
    "g.figure.subplots_adjust(hspace=-0.9)\n",
    "plt.show()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ecf3f3-13ee-41ef-b33d-b67268ff0c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values/Missing values\n",
    "\n",
    "\n",
    "#poverty\n",
    "missing_values = p_df.select([count(when(col(c).isNull(), c)).alias(c) for c in p_df.columns])\n",
    "missing_values.show()\n",
    "\n",
    "\n",
    "# income\n",
    "missing_values_i = income_data.select([count(when(col(c).isNull() | isnan(col(c)), c)).alias(c) for c in income_data.columns])\n",
    "missing_values_i.show()\n",
    "\n",
    "\n",
    "# gender\n",
    "missing_values_g = gender_ineq_data.select([count(when(col(c).isNull() | isnan(col(c)), c)).alias(c) for c in gender_ineq_data.columns])\n",
    "missing_values_g.show()\n",
    "\n",
    "\n",
    "#Check for any duplicate \n",
    "#poverty\n",
    "p_rowsduplicate_rows = p_df.count()- p_df.dropDuplicates().count()\n",
    "print(f\"\\n p_rowsduplicate_rows:{p_rowsduplicate_rows}\" )\n",
    "#income\n",
    "i_rowsduplicate_rows = i_df.count()- i_df.dropDuplicates().count()\n",
    "print(f\"\\n i_rowsduplicate_rows:{i_rowsduplicate_rows}\" )\n",
    "#gender\n",
    "g_rowsduplicate_rows = g_df.count()- g_df.dropDuplicates().count()\n",
    "print(f\"\\n g_rowsduplicate_rows:{g_rowsduplicate_rows}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5a1ead-8d7e-4e1f-b6a3-9b0b626fdf4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o72.csv.\n: java.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m columns_to_keep_p \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation_Deprivation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealth_Deprivation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiving_Standards\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPopulation_Below_National_Poverty_Line\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPopulation_Below_1_25_per_Day\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m p_df_s \u001b[38;5;241m=\u001b[39m poverty_data\u001b[38;5;241m.\u001b[39mselect(columns_to_keep_p)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mp_df_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPoverty_dataset_selected.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m selected_columns_i \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuman Development Groups\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2010)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2011)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2012)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2013)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2014)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2015)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2016)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2017)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2018)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2019)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2020)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInequality in income (2021)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m i_df_s \u001b[38;5;241m=\u001b[39m income_data\u001b[38;5;241m.\u001b[39mselect(selected_columns_i)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:1864\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[0;32m   1847\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   1848\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1862\u001b[0m     lineSep\u001b[38;5;241m=\u001b[39mlineSep,\n\u001b[0;32m   1863\u001b[0m )\n\u001b[1;32m-> 1864\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o72.csv.\n: java.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:850)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n"
     ]
    }
   ],
   "source": [
    "#3.1 filtering unnecessary cols\n",
    "\n",
    "\n",
    "#poverty\n",
    "columns_to_keep_p = ['Country', 'Education_Deprivation', 'Health_Deprivation', 'Living_Standards', 'Population_Below_National_Poverty_Line', 'Population_Below_1_25_per_Day']\n",
    "p_df_s = poverty_data.select(columns_to_keep_p)\n",
    "p_df_s.write.csv('Poverty_dataset_selected.csv', header=True, mode='overwrite')\n",
    "\n",
    "\n",
    "selected_columns_i = ['Country', 'Human Development Groups', 'Inequality in income (2010)', 'Inequality in income (2011)', 'Inequality in income (2012)', 'Inequality in income (2013)', 'Inequality in income (2014)', 'Inequality in income (2015)', 'Inequality in income (2016)', 'Inequality in income (2017)', 'Inequality in income (2018)', 'Inequality in income (2019)', 'Inequality in income (2020)', 'Inequality in income (2021)']\n",
    "i_df_s = income_data.select(selected_columns_i)\n",
    "i_df_s.write.csv('Income_dataset_selected.csv', header=True, mode='overwrite')\n",
    "\n",
    "\n",
    "selected_columns_g = ['Country', 'GII Rank', 'Gender Inequality Index (GII)', 'Population with Secondary Education (Female)', 'Population with Secondary Education (Male)']\n",
    "g_df_s = gender_ineq_data.select(selected_columns_g)\n",
    "g_df_s.write.csv('Gender_dataset_selected.csv', header=True, mode='overwrite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ce09a-c2f6-41d1-84dd-006f127d7a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
